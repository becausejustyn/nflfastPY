{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://srome.github.io/Bayesian-Hierarchical-Modeling-Applied-to-Fantasy-Football-Projections-for-Increased-Insight-and-Confidence/\n",
    "# data https://srome.github.io/files/bayesff/2013-2015_ff.csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('2013-2015_ff.csv')\n",
    "\n",
    "# One-hot-encode the positions\n",
    "data['pos_id'] = data['position']\n",
    "data = pd.get_dummies(data,columns=['position'])\n",
    "\n",
    "# Identify teams with integer\n",
    "ids = np.array([k for k in data['opp_team'].unique()])\n",
    "team_names = ids.copy()\n",
    "data['opp_team']=data['opp_team'].apply(lambda x : np.where(x == ids)[0][0])\n",
    "data['team']=data['team'].apply(lambda x : np.where(x == ids)[0][0])\n",
    "\n",
    "\n",
    "pos_ids = np.array([k for k in data['pos_id'].unique()])\n",
    "data['pos_id']=data['pos_id'].apply(lambda x : np.where(x == pos_ids)[0][0])\n",
    "data['diff_from_avg'] = data['score'] - data['7_game_avg']\n",
    "\n",
    "# We are using a single year for the analysis\n",
    "explore = data[data.apply(lambda x : x['year'] == 2013,axis=1)]\n",
    "train = data[data.apply(lambda x : x['year'] == 2014,axis=1)]\n",
    "test = data[data.apply(lambda x : x['year'] == 2015,axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Tale of Two Likelihoods\n",
    "\n",
    "Then came a modeling decision: when including position and rank based home/away advantages, an apparent indication of some degree of correlation between the features effecting convergence emerged. This negatively effected the convergence of the defense strength/weakness feature. So, I decided to approach this via two observables to improve convergence. I would tie the difference in the final projection directly to the defensive team by assigning it a data model with observables given by the score minus the projection average. Then, I added another likelihood which contains other corrective factors, hoping that it would help the defense feature converge and allow the corrective features to find a value. Indeed, this turned out to be the case the case.\n",
    "\n",
    "This technique is very similar to setting two objective functions in a minimization function, with some weighting between the two depending on the standard deviations of the distributions. You can see this connection if you think about how linear regression can be reframed as a Bayesian inference problem. Imagine a simple Bayesian model with a flat prior for $\\alpha$ and $\\sigma$ fixed being fitted to data ($x_{i}, y_{i}$.\n",
    "\n",
    "$y_{i} \\sim \\text{Normal}(\\alpha x_{i}, \\sigma)$\n",
    "$\\alpha \\sim \\text{FlatPrior}(- \\infty, \\infty)$\n",
    "\n",
    "Then, the posterior distribution for $\\mu(x)$ could be written \n",
    "\n",
    "$p(\\alpha | y_{i}, x_{i}, \\sigma) \\propto \\mathcal{L}(y_{i} | \\sigma, x_{i}, \\alpha) = \\mathcal{L}(y_{i} | \\sigma, x_{i}, \\alpha)$\n",
    "\n",
    "and recall the maximum a-priori estimate of α is the value of α that maximizes the likelihood, i.e. $\\arg \\max_{\\alpha} \\mathcal{L}(y_i | \\sigma, x_i, \\alpha)$. However, since the log is monotonic over $R+$, the following is true $\\arg \\max_{\\alpha} \\mathcal{L}(y_i | \\sigma, x_i, \\alpha) = \\arg \\max_\\alpha log \\mathcal{L} (y_i | \\sigma, x_i, \\alpha)$.\n",
    "So if we take the log of $\\mathcal{L}$, which is the PDF for the Normal distribution, we get for some constant c\n",
    "\n",
    "$\\log \\mathcal{L}(y_{i}| \\sigma, x_{i}, \\alpha) = \\log \\left(\\prod_{i=1}^{n} \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-(y_{i}- \\alpha x_{i})^{2}}{2\\sigma^{2}}}  \\right) = \\sum_{i=1}^{n} - \\frac{1}{2\\sigma^{2}} (y_{i}- \\alpha x_{i})^{2} + c$\n",
    "\n",
    "as the equation we want to maximize. Of course, to maximize this equation, we have to choose $\\alpha$ that makes the non-constant fraction as close to zero as possible! This is equivalent to the least squares minimization problem: find $\\alpha$ which minimizes\n",
    "\n",
    "$\\underset{a}{\\min} \\sum_{i=1}^{n}(y_{i}- \\alpha x_{i})^{2}$\n",
    "\n",
    "Therefore, we included the defensive team terms essentially twice, they will have a higher influence over the resulting optimization “in the background” of the sampling. If we allow each standard deviation to vary, then the sampling algorithm will find the weighting of the objection functions to find the best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bayesian Hierarchical Model\n",
    "\n",
    "This model is only as good as its base projection. A key idea behind the model is to take a projection that is “pretty good” and try to correct it with external information about the game. In particular, we try to use dynamics of each team vs. each position to make the correction, along with the advantage of the home team. Of course, if we had more data, we could do our own projection using a model inside the hierarchy for example, but that is outside of the scope of this post. For our purposes, we will use the 7 game average of the player’s fantasy points as our base model. It would be a simple exercise to use either ESPN or Yahoo’s projections instead.\n",
    "\n",
    "A key aspect of this model is the partial pooling across different levels. The partial pooling is essential to performance in this case, possibly due to the large (-ish) number of variables coming from each distribution. Partial pooling allows you to give different coefficients to the same variables depending on selected factors, and the coefficients are drawn from a common distribution. This is different from other approaches– typical linear regression “pools” all measurements by giving a single regression coefficient to each variable, while the alternative of no pooling is giving each row its own unique equation. This partial pooling allows information to be shared across variables, and one example of which is such partial pooling can pull posterior distributions of the coefficients closer together.\n",
    "\n",
    "The players’ fantasy scores $p_i$ for game i’s difference with the previous 7 game average p - i is modeled as a Student T distribution (due to extremes) with data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen Shot 2022-09-06 at 12.17.26 pm\n",
    "# Screen Shot 2022-09-06 at 12.17.37 pm\n",
    "# Screen Shot 2022-09-06 at 12.17.45 pm\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "\n",
    "num_positions=4\n",
    "ranks=4\n",
    "team_number = len(team_names)\n",
    "np.random.seed(182)\n",
    "\n",
    "with pm.Model() as mdl:\n",
    "    nu = pm.Exponential('nu minus one', 1/29.,shape=2) + 1 # from https://pymc-devs.github.io/pymc3/notebooks/BEST.html\n",
    "    err = pm.Uniform('std dev based on rank', 0, 100, shape=ranks)\n",
    "    err_b = pm.Uniform('std dev based on rank b', 0, 100, shape=ranks)\n",
    "\n",
    "    # Theano shared variables to change at test time\n",
    "    player_home = theano.shared(np.asarray(train['is_home'].values, dtype = int))\n",
    "    player_avg = theano.shared(np.asarray((train['7_game_avg']).values, dtype = float))\n",
    "    player_opp = theano.shared(np.asarray((train['opp_team']).values, dtype = int))\n",
    "    player_team = theano.shared(np.asarray((train['team']).values, dtype = int))\n",
    "    player_rank = theano.shared(np.asarray((train['rank']-1).values, dtype = int))\n",
    "    qb = theano.shared(np.asarray((train['position_QB']).values.astype(int), dtype = int))\n",
    "    wr = theano.shared(np.asarray((train['position_WR']).values.astype(int), dtype = int))\n",
    "    rb = theano.shared(np.asarray((train['position_RB']).values.astype(int), dtype = int))\n",
    "    te = theano.shared(np.asarray((train['position_TE']).values.astype(int), dtype = int))\n",
    "    pos_id = theano.shared(np.asarray((train['pos_id']).values, dtype = int))\n",
    "\n",
    "    # Defensive ability of the opposing team vs. each position, partially pooled\n",
    "    opp_def = pm.Normal('opp team prior',0, sd=100**2, shape=num_positions)\n",
    "    opp_qb = pm.Normal('defensive differential qb', opp_def[0], sd=100**2, shape=team_number)\n",
    "    opp_wr = pm.Normal('defensive differential wr', opp_def[1], sd=100**2, shape=team_number)\n",
    "    opp_rb = pm.Normal('defensive differential rb', opp_def[2], sd=100**2, shape=team_number)\n",
    "    opp_te = pm.Normal('defensive differential te', opp_def[3], sd=100**2, shape=team_number)\n",
    "    \n",
    "    # Partially pooled ability of the player's rank partially pooled based on position\n",
    "    home_adv = pm.Normal('home additivie prior', 0, 100**2,shape = num_positions)     \n",
    "    away_adv = pm.Normal('away additivie prior', 0, 100**2,shape = num_positions)     \n",
    "    pos_home_qb = pm.Normal('home differential qb',home_adv[0],10**2, shape = ranks)\n",
    "    pos_home_rb = pm.Normal('home differential rb',home_adv[1],10**2, shape = ranks)\n",
    "    pos_home_te = pm.Normal('home differential te',home_adv[2],10**2, shape = ranks)\n",
    "    pos_home_wr = pm.Normal('home differential wr',home_adv[3],10**2, shape = ranks)\n",
    "    pos_away_qb = pm.Normal('away differential qb',away_adv[0],10**2, shape = ranks)\n",
    "    pos_away_rb = pm.Normal('away differential rb',away_adv[1],10**2, shape = ranks)\n",
    "    pos_away_wr = pm.Normal('away differential wr',away_adv[2],10**2, shape = ranks)\n",
    "    pos_away_te = pm.Normal('away differential te',away_adv[3],10**2, shape = ranks)\n",
    "\n",
    "    # First likelihood where the player's difference from average is explained by defensive abililty\n",
    "    def_effect = qb*opp_qb[player_opp]+ wr*opp_wr[player_opp]+ rb*opp_rb[player_opp]+ te*opp_te[player_opp]\n",
    "    like1 = pm.StudentT('Diff From Avg', mu=def_effect, sd=err_b[player_rank],nu=nu[1], observed = train['diff_from_avg'])\n",
    "    \n",
    "    # Second likelihood where the score is predicted by defensive power plus other smaller factors\n",
    "    mu = player_avg + def_effect\n",
    "    mu += rb*pos_home_rb[player_rank]*(player_home) + wr*pos_home_wr[player_rank]*(player_home) \n",
    "    mu += qb*pos_home_qb[player_rank]*(player_home) + te*pos_home_te[player_rank]*(player_home) \n",
    "    mu += rb*pos_away_rb[player_rank]*(1-player_home) + wr*pos_away_wr[player_rank]*(1-player_home) \n",
    "    mu += qb*pos_away_qb[player_rank]*(1-player_home) + te*pos_away_te[player_rank]*(1-player_home) \n",
    "    like2 = pm.StudentT('Score', mu=mu, sd=err[player_rank], nu=nu[0], observed=train['score'])\n",
    "\n",
    "    # Training!\n",
    "    trace=pm.sample(10000, pm.Metropolis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=trace[-5000::3]\n",
    "%matplotlib inline\n",
    "_=pm.traceplot(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we were aware from the beginning that certain inputs would be inherently unpredictable as we are missing enough features and data to fully describe the phenomenon in the data set. This manifests itself in poor convergence in certain variables, but overall we decided this was worthwhile in our case because we want the model to indicate projections we should be confident in as well as some quantitative metrics on the teams. As we can see, the posterior distributions have reasonably converged and there is no obvious indication of a problem outside of our a priori assumption that certain variables would have poor convergence due to a variety of factors. If one were to see terrible results on the test set, that would be another indication of a model that either is simply poor and/or has not converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projecting on the Test Set\n",
    "\n",
    "# Set the shared variables to the test set values\n",
    "player_home.set_value(np.asarray(test['is_home'].values, dtype = int))\n",
    "player_avg.set_value(np.asarray((test['7_game_avg']).values, dtype = float))\n",
    "player_opp.set_value(np.asarray((test['opp_team']).values, dtype = int))\n",
    "player_rank.set_value(np.asarray((test['rank']-1).values, dtype = int))\n",
    "pos_id.set_value(np.asarray((test['pos_id']).values, dtype = int))\n",
    "player_team.set_value(np.asarray((test['team']).values, dtype = int))\n",
    "qb.set_value(np.asarray((test['position_QB']).values.astype(int), dtype = int))\n",
    "wr.set_value(np.asarray((test['position_WR']).values.astype(int), dtype = int))\n",
    "rb.set_value(np.asarray((test['position_RB']).values.astype(int), dtype = int))\n",
    "te.set_value(np.asarray((test['position_TE']).values.astype(int), dtype = int))\n",
    "\n",
    "ppc=pm.sample_ppc(tr, samples=1000, model= mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error\n",
    "#The first metric we will look at is for point estimates. We will average over the posterior distribution to generate a point estimate for each data point and then calculate it’s mean absolute error. We will then compare it to the error of our base projection we used, the 7 day average.\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print('Projection Mean Absolute Error:', mean_absolute_error(test.loc[:,'score'].values, ppc['Score'].mean(axis=0)))\n",
    "print('7 Day Average Mean Absolute Error:', mean_absolute_error(test.loc[:,'score'].values, test.loc[:,'7_game_avg'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence in Projections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_sd = d['sd'].max()\n",
    "plt.figure(figsize=(8,5))\n",
    "ax=plt.gca()\n",
    "ax.plot(np.linspace(0,max_sd,30), np.array([d[d['sd'] <= k]['proj MAE'].mean() for k in np.linspace(0,max_sd,30)]))\n",
    "ax.plot(np.linspace(0,max_sd,30), np.array([d[d['sd'] <= k]['historical avg MAE'].mean() for k in np.linspace(0,max_sd,30)]), color='r')\n",
    "ax.set_ylabel('Mean Absolute Error')\n",
    "ax.set_xlabel('Standard Deviation Cutoff')\n",
    "ax.set_title('MAE for Projections w/ SDs Under Cutoff')\n",
    "ax.legend(['Bayesian Mean Projection', 'Rolling 7 Game Mean'], loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = pd.DataFrame({'projection':  tr['defensive differential rb'].mean(axis=0), 'sd' : tr['defensive differential rb'].std(axis=0),'name': team_names})\n",
    "f=plt.figure(figsize=(8,10))\n",
    "plt.errorbar(x=t['projection'],y=range(1,len(t)+1),xerr=t['sd'], lw=3, fmt='|')\n",
    "plt.title('Team Effect\\'s on RB Point Average (2014)')\n",
    "end=plt.yticks(range(1,len(t)+1), [name for name in t['name']])\n",
    "plt.xlim([-6,8])\n",
    "plt.xlabel('Change in opponent\\'s RB\\'s average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = pd.DataFrame({'projection':  tr['defensive differential qb'].mean(axis=0), 'sd' : tr['defensive differential qb'].std(axis=0),'name': team_names})\n",
    "f=plt.figure(figsize=(8,10))\n",
    "plt.errorbar(x=t['projection'],y=range(1,len(t)+1),xerr=t['sd'], lw=3, fmt='|')\n",
    "plt.title('Team\\'s Effect on QB Point Average (2014)')\n",
    "end=plt.yticks(range(1,len(t)+1), [name for name in t['name']])\n",
    "plt.xlim([-11.5,10])\n",
    "plt.xlabel('Change in opponent\\'s QB\\'s average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = pd.DataFrame({'projection':  tr['defensive differential te'].mean(axis=0), 'sd' : tr['defensive differential te'].std(axis=0),'name': team_names})\n",
    "f=plt.figure(figsize=(8,10))\n",
    "plt.errorbar(x=t['projection'],y=range(1,len(t)+1),xerr=t['sd'], lw=3, fmt='|')\n",
    "plt.title('Team Effect\\'s on TE Point Average (2014)')\n",
    "end=plt.yticks(range(1,len(t)+1), [name for name in t['name']])\n",
    "plt.xlim([-8,8])\n",
    "plt.xlabel('Change in opponent\\'s TE\\'s average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = pd.DataFrame({'projection':  tr['defensive differential wr'].mean(axis=0), 'sd' : tr['defensive differential wr'].std(axis=0),'name': team_names})\n",
    "f=plt.figure(figsize=(8,10))\n",
    "plt.errorbar(x=t['projection'],y=range(1,len(t)+1),xerr=t['sd'], lw=3, fmt='|')\n",
    "plt.title('Team\\'s Effect on WR Point Average (2014)')\n",
    "end=plt.yticks(range(1,len(t)+1), [name for name in t['name']])\n",
    "plt.xlim([-4.5,3.1])\n",
    "plt.xlabel('Change in opponent\\'s WR\\'s average')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
