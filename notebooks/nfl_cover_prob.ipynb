{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C7pE2wndJ1dj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## A lot of the below follows this guide youtube.com/watch?v=GrJP9FLV3FE&t=407s ##\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OKbdcvgWviMS"
      },
      "outputs": [],
      "source": [
        "#output_folder = '/content/drive/MyDrive/Colab Notebooks/data'\n",
        "output_folder = 'data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uDwsq4_vKDBM"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/nfl_df_cv.zip', low_memory=False, index_col=False)\n",
        "df = pd.read_csv('data/nfl_df_cv.zip', low_memory=False, index_col=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NprtBR2Kre88"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDcm4FnVtSgZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLwcxVp_wzxh"
      },
      "source": [
        "<details>\n",
        "<summary><h3> Wrangling </h3></summary>\n",
        "I had the data on my local machine so I read it in, then dropped columns that I did not need to decrease how much on disk memory was used\n",
        "\n",
        "```python\n",
        "df = pd.concat([nfl.import_pbp_data(years = range(1999, 2022))])\n",
        "\n",
        "df = df[[\n",
        "  'play_id', 'game_id', 'season', 'posteam', 'posteam_type', 'spread_line', \n",
        "  'game_seconds_remaining', 'play_type', 'game_half', 'result', \n",
        "  'score_differential', 'half_seconds_remaining', 'game_seconds_remaining', \n",
        "  'down', 'ydstogo', 'yardline_100', 'posteam_timeouts_remaining', 'defteam_timeouts_remaining' \n",
        "]]\n",
        "```\n",
        "\n",
        "The dataset is 1098040 `rows` by 382 `columns` so you might need to break this into multiple steps. Since I had the data locally it was slightly quicker for me.  \n",
        "\n",
        "Using `R` you can use\n",
        "\n",
        "```r\n",
        "library(tidyverse)\n",
        "\n",
        "# #https://raw.githubusercontent.com/guga31bb/nflfastR-data/master/data/play_by_play_{x}.rds\n",
        "df <- purrr::map_df(c(1999:2021), function(x){\n",
        "  read_rds(glue::glue('~/Downloads/nfl_pbp/play_by_play_{x}.rds'))\n",
        "  })\n",
        "\n",
        "pbp <- df |>\n",
        "  select(play_id, game_id, season, posteam, posteam_type, \n",
        "         result, play_type, down, ydstogo, yardline_100,\n",
        "         spread_line, game_seconds_remaining, game_half, \n",
        "         score_differential, half_seconds_remaining, \n",
        "         posteam_timeouts_remaining, defteam_timeouts_remaining)\n",
        "```\n",
        "\n",
        "Continue\n",
        "\n",
        "A lot of wrangling was done, which is why I saved the output. The steps taken were\n",
        "\n",
        "```python\n",
        "## create some new variables for the model ##\n",
        "## most features taken directly from nflfastR ##\n",
        "\n",
        "## SPREAD_LINE_DIFFERENTIAL ##\n",
        "## instead of a point differential, use a spread line differential ##\n",
        "## ie how close is the team to covering ##\n",
        "df['spread_line_differential'] = np.where(\n",
        "    df['posteam_type'] == 'home',\n",
        "    -1 * df['spread_line'] + df['score_differential'],\n",
        "    np.where(\n",
        "        df['posteam_type'] == 'away',\n",
        "        df['spread_line'] + df['score_differential'],\n",
        "        np.nan\n",
        "    ))\n",
        "\n",
        "## elapsed share, spread_time, and Diff_Time_Ratio are all custom features from nflfastR's model ##\n",
        "## https://raw.githubusercontent.com/mrcaseb/nflfastR/master/R/helper_add_ep_wp.R ##\n",
        "## elapsed share ##\n",
        "df['elapsed_share'] = (\n",
        "    (3600 - df['game_seconds_remaining']) / 3600\n",
        ")\n",
        "\n",
        "df['posteam_spread'] = np.where(\n",
        "    df['posteam_type'] == 'home',\n",
        "    df['spread_line'],\n",
        "    -1 * df['spread_line']\n",
        ")\n",
        "\n",
        "## spread_time ##\n",
        "df['spread_time'] = df['posteam_spread'] * np.exp(-4 * df['elapsed_share'])\n",
        "\n",
        "## Diff_Time_Ratio ##\n",
        "df['diff_time_ratio'] = df['score_differential'] / np.exp(-4 * df['elapsed_share'])\n",
        "\n",
        "## RECEIVE_2H_KO ##\n",
        "## determine who received the first kickoff ##\n",
        "kickoff_df = df[df['play_type'] == 'kickoff'].groupby(['game_id'])[['game_id','posteam_type']].head(1)\n",
        "\n",
        "## add back to df ##\n",
        "df = pd.merge(df,\n",
        "kickoff_df.rename(columns={\n",
        "    'posteam_type' : 'received_first_ko'\n",
        "    }),\n",
        "    on=['game_id'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "## create receive 2nd half ko variable ##\n",
        "df['receive_2h_ko'] = np.where(\n",
        "    (df['game_half'] == 'Half1') & (df['posteam_type'] != df['received_first_ko']),\n",
        "    1, 0\n",
        ")\n",
        "\n",
        "## IS_PAT || denote if a play is a pat ##\n",
        "df['is_pat'] = np.where(\n",
        "    df['play_type'] == 'extra_point',\n",
        "    1, 0\n",
        ")\n",
        "\n",
        "## POSTEAM_IS_HOME || turn posteam_type into a boolean ##\n",
        "df['posteam_is_home'] = np.where(\n",
        "    df['posteam_type'] == 'home',\n",
        "    1, np.where(\n",
        "        df['posteam_type'] == 'away',\n",
        "        0, np.nan\n",
        "    ))\n",
        "\n",
        "## COVER_RESULT ##\n",
        "df['cover_result'] = np.where(\n",
        "    df['posteam_type'] == 'home',\n",
        "    np.where(\n",
        "        -1 * df['spread_line'] + df['result'] > 0,\n",
        "        1, 0),\n",
        "    np.where(\n",
        "        df['posteam_type'] == 'away',\n",
        "        np.where(\n",
        "            df['spread_line'] + -1 * df['result'] > 0,\n",
        "            1, 0),\n",
        "        np.nan\n",
        "    ))\n",
        "\n",
        "model_df = df[[\n",
        "    ## only needed for train/test split ##\n",
        "    'game_id',\n",
        "    'season',\n",
        "    ## dependent var ##\n",
        "    'cover_result',\n",
        "    ## independent vars from WP model ##\n",
        "    'spread_time',\n",
        "    'score_differential',\n",
        "    'diff_time_ratio',\n",
        "    'posteam_is_home',\n",
        "    'half_seconds_remaining',\n",
        "    'game_seconds_remaining',\n",
        "    'down',\n",
        "    'ydstogo',\n",
        "    'yardline_100',\n",
        "    'posteam_timeouts_remaining',\n",
        "    'defteam_timeouts_remaining',\n",
        "    'receive_2h_ko',\n",
        "    ## new features for CP model ##\n",
        "    'is_pat',\n",
        "    'spread_line_differential',\n",
        "]].copy()\n",
        "\n",
        "## remove NAs ##\n",
        "model_df = model_df.dropna()\n",
        "\n",
        "# save as a .zip to reduce size \n",
        "model_df.to_csv('nfl_df_cv.zip', index=False, compression=dict(method='zip', archive_name='nfl_df_cv.csv'))\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "sHN99oNJKoKC",
        "outputId": "32ab3d59-0e06-455b-c6f2-6531431c5ae7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>season</th>\n",
              "      <th>cover_result</th>\n",
              "      <th>spread_time</th>\n",
              "      <th>score_differential</th>\n",
              "      <th>diff_time_ratio</th>\n",
              "      <th>posteam_is_home</th>\n",
              "      <th>half_seconds_remaining</th>\n",
              "      <th>game_seconds_remaining</th>\n",
              "      <th>down</th>\n",
              "      <th>ydstogo</th>\n",
              "      <th>yardline_100</th>\n",
              "      <th>posteam_timeouts_remaining</th>\n",
              "      <th>defteam_timeouts_remaining</th>\n",
              "      <th>receive_2h_ko</th>\n",
              "      <th>is_pat</th>\n",
              "      <th>spread_line_differential</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1999_01_ARI_PHI</td>\n",
              "      <td>1999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10</td>\n",
              "      <td>77.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999_01_ARI_PHI</td>\n",
              "      <td>1999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>77.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1999_01_ARI_PHI</td>\n",
              "      <td>1999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9</td>\n",
              "      <td>76.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           game_id  season  cover_result  spread_time  score_differential  \\\n",
              "0  1999_01_ARI_PHI    1999           1.0         -3.0                 0.0   \n",
              "1  1999_01_ARI_PHI    1999           1.0         -3.0                 0.0   \n",
              "2  1999_01_ARI_PHI    1999           1.0         -3.0                 0.0   \n",
              "\n",
              "   diff_time_ratio  posteam_is_home  half_seconds_remaining  \\\n",
              "0              0.0              1.0                  1800.0   \n",
              "1              0.0              1.0                  1800.0   \n",
              "2              0.0              1.0                  1800.0   \n",
              "\n",
              "   game_seconds_remaining  down  ydstogo  yardline_100  \\\n",
              "0                  3600.0   1.0       10          77.0   \n",
              "1                  3600.0   2.0       10          77.0   \n",
              "2                  3600.0   3.0        9          76.0   \n",
              "\n",
              "   posteam_timeouts_remaining  defteam_timeouts_remaining  receive_2h_ko  \\\n",
              "0                         3.0                         3.0              0   \n",
              "1                         3.0                         3.0              0   \n",
              "2                         3.0                         3.0              0   \n",
              "\n",
              "   is_pat  spread_line_differential  \n",
              "0       0                       3.0  \n",
              "1       0                       3.0  \n",
              "2       0                       3.0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BN0Z5DAKp3R",
        "outputId": "08800ee5-d565-4ac9-9380-881f6d9a1f28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(913762, 17)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XQG47_UuLQg"
      },
      "source": [
        "## MODEL \n",
        "\n",
        "Split dependent and independent data frames since data is at the play level and we want to predict something that occurs at the game level, we can't just take a random sample of plays instead, we will take a random sample of games and apply test/train sets that way this ensures no game has plays in both the test and train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J1rbLtequGje"
      },
      "outputs": [],
      "source": [
        "## we'll also hold out the last two seasons (2020 and 2021) for validation ##\n",
        "model_construction_df = df[df['season'] < 2020].copy()\n",
        "model_validation_df = df[df['season'] >= 2020].copy()\n",
        "\n",
        "## get df of unique games ##\n",
        "set_key_df = model_construction_df.groupby(['game_id'])['game_id'].head(1).reset_index()[['game_id']].copy()\n",
        "\n",
        "## assign to test / train randomly ##\n",
        "set_key_df['rand_float'] = np.random.uniform(\n",
        "    low=0,\n",
        "    high=1,\n",
        "    size=len(set_key_df)\n",
        ")\n",
        "\n",
        "## assign set ##\n",
        "set_key_df['is_training_set'] = np.where(\n",
        "    set_key_df['rand_float'] > .33,\n",
        "    1, 0\n",
        ")\n",
        "\n",
        "## match back to model df ##\n",
        "model_construction_df = pd.merge(\n",
        "    model_construction_df,\n",
        "    set_key_df[['game_id', 'is_training_set']],\n",
        "    on=['game_id'],\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aE0CctMquGgn"
      },
      "outputs": [],
      "source": [
        "## create training and test sets ##\n",
        "training_df = model_construction_df[model_construction_df['is_training_set'] == 1].copy()\n",
        "test_df = model_construction_df[model_construction_df['is_training_set'] == 0].copy()\n",
        "\n",
        "## create x and y versions ##\n",
        "X_train = training_df.drop(columns=['game_id', 'season', 'is_training_set', 'cover_result']).copy()\n",
        "X_test = test_df.drop(columns=['game_id', 'season', 'is_training_set', 'cover_result']).copy()\n",
        "\n",
        "y_train = training_df['cover_result'].copy()\n",
        "y_test = test_df['cover_result'].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMh2DVoxuGe2"
      },
      "outputs": [],
      "source": [
        "## create first model to make sure evrything works ##\n",
        "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
        "clf_xgb.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    verbose=True,\n",
        "    early_stopping_rounds = 10,\n",
        "    eval_metric='aucpr',\n",
        "    eval_set=[(X_test, y_test)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YGK5Rapd5LKM"
      },
      "outputs": [],
      "source": [
        "## Hyperparameter Optimization ##\n",
        "## do some hyper parameter optimization ##\n",
        "## Round 1 ##\n",
        "param_grid = {\n",
        "    'max_depth' : [3, 4, 5, 6, 7],\n",
        "    'learning_rate' : [0.1, 0.05, 0.01, 0.025, 0.005],\n",
        "    'gamma' : [0.25],\n",
        "    'reg_lambda' : [4, 5, 6, 7, 8],\n",
        "    'n_estimators' : [100, 500, 1000, 1125, 1250],\n",
        "}\n",
        "\n",
        "## set up grid search ##\n",
        "optimal_params = GridSearchCV(\n",
        "    estimator=xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.75\n",
        "    ),\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    verbose=0,\n",
        "    cv=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yLlanarU5Xok",
        "outputId": "8571ea61-619a-4fb7-be97-331ca12b6563"
      },
      "outputs": [],
      "source": [
        "## fit ##\n",
        "optimal_params.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    eval_set=[(X_test, y_test)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a987uai62DaC",
        "outputId": "0bca0d52-3776-4227-802a-139ef9534296"
      },
      "outputs": [],
      "source": [
        "clf_xgb.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYNr-qgQ4z7T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doAcNU1MuGbv"
      },
      "outputs": [],
      "source": [
        "## Round 1 Results ##\n",
        "## {'gamma': 0., 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'reg_lambda': 1}\n",
        "\n",
        "## Round 2 ##\n",
        "param_grid = {\n",
        "    'max_depth' : [5, 6, 7],\n",
        "    'learning_rate' : [0.005, 0.01, 0.025],\n",
        "    'gamma' : [.25],\n",
        "    'reg_lambda' : [6, 8, 10],\n",
        "    'n_estimators' : [1000, 1250, 1500],\n",
        "}\n",
        "\n",
        "## {'gamma': 0.25, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'reg_lambda': 6}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddW7_J1-uGaD"
      },
      "outputs": [],
      "source": [
        "## Round 3 ##\n",
        "param_grid = {\n",
        "    'max_depth' : [5],\n",
        "    'learning_rate' : [0.01],\n",
        "    'gamma' : [.25],\n",
        "    'reg_lambda' : [2, 4, 6],\n",
        "    'n_estimators' : [1000, 1125],\n",
        "}\n",
        "\n",
        "## {'gamma': 0.25, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'reg_lambda': 6}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMfgKD0fuGXK"
      },
      "outputs": [],
      "source": [
        "## set up grid search ##\n",
        "optimal_params = GridSearchCV(\n",
        "    estimator=xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.75\n",
        "    ),\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    verbose=0,\n",
        "    cv=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udOaMi_cuGU_"
      },
      "outputs": [],
      "source": [
        "## fit ##\n",
        "optimal_params.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    eval_set=[(X_test, y_test)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2N73n7auGSn"
      },
      "outputs": [],
      "source": [
        "## rerun w/ tuned params ##\n",
        "clf_xgb = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    gamma=0.25,\n",
        "    max_depth=5,\n",
        "    reg_lambda=6,\n",
        "    learning_rate=0.01,\n",
        "    n_estimators=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SPCaLpfuGQN"
      },
      "outputs": [],
      "source": [
        "clf_xgb.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    verbose=True,\n",
        "    early_stopping_rounds = 10,\n",
        "    eval_metric='aucpr',\n",
        "    eval_set=[(X_test, y_test)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPMqDwB9uGN0"
      },
      "outputs": [],
      "source": [
        "## save model for future use ##\n",
        "clf_xgb.save_model(\n",
        "    '{0}/cp.model'.format(output_folder)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ2uudp1uGLw"
      },
      "outputs": [],
      "source": [
        "## a function for saving csvs of model performance locally. Not necessary to run ##\n",
        "def score_models(model_arrays):\n",
        "    bin_dfs = []\n",
        "    confusion_dfs = []\n",
        "    metric_dfs = []\n",
        "    for i in model_arrays:\n",
        "        df = i[0].copy()\n",
        "        output_name = i[1]\n",
        "        ## create predictions ##\n",
        "        df['cover_prob'] = clf_xgb.predict_proba(df.drop(columns=['cover_result']))[:,1]\n",
        "        ## bins ##\n",
        "        bins = np.linspace(0, 1, 100)\n",
        "        binned_df = df.groupby(\n",
        "            np.digitize(df['cover_prob'], bins)\n",
        "        ).agg(\n",
        "            cover_average = ('cover_result', 'mean'),\n",
        "            observations = ('cover_result', 'count'),\n",
        "        ).reset_index().rename(columns={\n",
        "            'index' : 'cover_prob'\n",
        "        })\n",
        "        binned_df['set_type'] = output_name\n",
        "        ## confusion ##\n",
        "        df['true_pos'] = np.where(\n",
        "            (df['cover_prob'] > .5) &\n",
        "            (df['cover_result'] == 1),\n",
        "            1, 0)\n",
        "        df['false_pos'] = np.where(\n",
        "            (df['cover_prob'] > .5) &\n",
        "            (df['cover_result'] == 0),\n",
        "            1, 0)\n",
        "        df['true_neg'] = np.where(\n",
        "            (df['cover_prob'] < .5) &\n",
        "            (df['cover_result'] == 0),\n",
        "            1, 0)\n",
        "        df['false_neg'] = np.where(\n",
        "            (df['cover_prob'] < .5) &\n",
        "            (df['cover_result'] == 1),\n",
        "            1, 0)\n",
        "        confusion_df = pd.DataFrame([{\n",
        "            'set_type:' : output_name,\n",
        "            'true_positive' : df['true_pos'].sum(),\n",
        "            'false_positive' : df['false_pos'].sum(),\n",
        "            'true_negative' : df['true_neg'].sum(),\n",
        "            'false_negative' : df['false_neg'].sum(),\n",
        "        }])\n",
        "        ## log loss ##\n",
        "        log_loss_score = log_loss(\n",
        "            df['cover_result'],\n",
        "            df['cover_prob'])\n",
        "        auc = roc_auc_score(\n",
        "            df['cover_result'],\n",
        "            df['cover_prob'])\n",
        "        metric_df = pd.DataFrame([{\n",
        "            'set_type:' : output_name,\n",
        "            'log_loss' : log_loss_score,\n",
        "            'roc_auc' : auc,\n",
        "        }])\n",
        "        bin_dfs.append(binned_df)\n",
        "        confusion_dfs.append(confusion_df)\n",
        "        metric_dfs.append(metric_df)\n",
        "    bin_output = pd.concat(bin_dfs)\n",
        "    confusion_output = pd.concat(confusion_dfs)\n",
        "    metrics_output = pd.concat(metric_dfs)\n",
        "    ## output ##\n",
        "    bin_output.to_csv(\n",
        "        '{0}/binned_results.csv'.format(\n",
        "            output_folder))\n",
        "    confusion_output.to_csv(\n",
        "        '{0}/confusion_results.csv'.format(\n",
        "            output_folder))\n",
        "    metrics_output.to_csv(\n",
        "        '{0}/metric_results.csv'.format(\n",
        "            output_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpGS9-kPuGI1"
      },
      "outputs": [],
      "source": [
        "test_arrays = [\n",
        "    [training_df.drop(columns=['game_id', 'season', 'is_training_set']).copy(),\n",
        "        'training'],\n",
        "    [test_df.drop(columns=['game_id', 'season', 'is_training_set']).copy(),\n",
        "        'test'],\n",
        "    [model_validation_df.drop(columns=['game_id', 'season']).copy(),\n",
        "        'validate'],\n",
        "        ]\n",
        "\n",
        "score_models(test_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjD083CtuGGe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9orPdHuGEE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Iuc6dJuGBg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v23Qf1NuF_G"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gLDRiI-JSie"
      },
      "outputs": [],
      "source": [
        "import nfl_data_py as nfl\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.ticker as plticker\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "plt.style.use('seaborn-talk')\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "pd.set_option('display.max_columns', 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfe-1pFlMnkt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JNo1X3AOGRH",
        "outputId": "ef146491-d245-4d65-9ba4-3d72937f7a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2020\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq_muMvSOXSm",
        "outputId": "c19ac150-79ee-4a7f-cf04-d6f37c39cbed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data not available for 2021\n",
            "Downcasting floats.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJT2aFQJizW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpI8mgMnJiww"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fv4L6i5JiuI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIsFswsOQLSw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ywP6VB7Jiri",
        "outputId": "31734324-082d-47a5-e9ca-42a17956b24e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['play_id', 'game_id', 'old_game_id', 'home_team', 'away_team',\n",
              "       'season_type', 'week', 'posteam', 'posteam_type', 'defteam',\n",
              "       ...\n",
              "       'possession_team', 'offense_formation', 'offense_personnel',\n",
              "       'defenders_in_box', 'defense_personnel', 'number_of_pass_rushers',\n",
              "       'offense_players', 'n_offense', 'defense_players', 'n_defense'],\n",
              "      dtype='object', length=382)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGwk3iMPJio4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUcB7-2yJimb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "nfl_cover_prob.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
